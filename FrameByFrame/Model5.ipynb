{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer with documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Global Variables and Hyperparameters ---\n",
    "base_path = './kaggle/input/nfl-big-data-bowl-2026-prediction/train'\n",
    "lr = .001\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "num_weeks = 9\n",
    "load_prev_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ETL Helpers ---\n",
    "\n",
    "# Input: Array of input dataframes\n",
    "# Output: Dictionary of dataframes grouped by id\n",
    "def format_input(input):\n",
    "    ipt = pd.concat(input, ignore_index=True) # Concatenate all dfs into one\n",
    "    ipt = ipt[ipt['player_to_predict'] == True].copy(deep=True) # Filter to only players that matter\n",
    "\n",
    "    # Add velocity component column\n",
    "    dir_rad = np.deg2rad(ipt['dir'])\n",
    "    ipt['vx'] = ipt['s'] * np.sin(dir_rad)\n",
    "    ipt['vy'] = ipt['s'] * np.cos(dir_rad)\n",
    "\n",
    "    # Add orientation components\n",
    "    o_rad = np.deg2rad(ipt['o'])\n",
    "    ipt['ox'] = np.sin(o_rad)\n",
    "    ipt['oy'] = np.cos(o_rad)\n",
    "\n",
    "    # Offense going left? 1 or -1\n",
    "    ipt['go_left'] = np.where(ipt['play_direction'] == 'left', 1, -1)\n",
    "\n",
    "    # Offensive player? 1 or -1\n",
    "    ipt['offensive_player'] = np.where(ipt['player_role'] == 'Targeted Receiver', 1, -1)\n",
    "\n",
    "    # Get useful columns only\n",
    "    # Constant variables: 'go_left', 'offensive_player', 'ball_land_x', 'ball_land_y', 'absolute_yardline_number', 'num_frames_output'\n",
    "    # Time variables : 'x', 'y', 'vx', 'vy', 'ox', 'oy', 'a', 'frame_id'\n",
    "    ipt = ipt[['game_id', 'play_id', 'nfl_id', 'x', 'y', 'vx', 'vy', 'ox', 'oy', 'go_left', 'offensive_player', 'a', 'ball_land_x', 'ball_land_y', 'absolute_yardline_number', 'frame_id', 'num_frames_output']]\n",
    "\n",
    "\n",
    "    # Create dictionary of dfs\n",
    "    ipt = {\n",
    "        f\"{gid}_{pid}_{nid}\": g\n",
    "        for (gid, pid, nid), g in ipt.groupby(['game_id', 'play_id', 'nfl_id'])\n",
    "    }\n",
    "    return ipt\n",
    "\n",
    "\n",
    "# Input: \n",
    "    # instance: Dataframe specific to game, nfl, and player ids\n",
    "    # frame: Current frame used for prediction\n",
    "# Output: List of (x0, x1, x2)\n",
    "    # x0, First input vector\n",
    "    # x1: First input array\n",
    "    # x2: Second input vector\n",
    "def build_inputs(instance, frame):\n",
    "    x0 = instance.iloc[-1][['go_left', 'offensive_player', 'ball_land_x', 'ball_land_y','absolute_yardline_number', 'num_frames_output']].values \n",
    "    x0 = np.concatenate([x0, [frame]]).astype(np.float32)#np(7,)\n",
    "    x1 = instance.iloc[-5:][['x','y','vx','vy','ox','oy','a','frame_id']].values.astype(np.float32) #np(5,8)\n",
    "    x2 = instance.iloc[-1][['x','y']].values.astype(np.float32) #np(2,)\n",
    "    return x0, x1, x2\n",
    "\n",
    "\n",
    "\n",
    "# Input: \n",
    "    # out: Target dataframe (use only to extract ids and get frame id)\n",
    "    # ipt: Dictionary of input dfs\n",
    "# Output: List of (x0, x1, x2, y)\n",
    "    # x0: First input vector\n",
    "    # x1: First input array\n",
    "    # x2: Second input vector\n",
    "    # y: Target vector\n",
    "def preprocess(out, ipt):\n",
    "    data = []\n",
    "    for _, row in out.iterrows():\n",
    "        fid = f\"{int(row['game_id'])}_{int(row['play_id'])}_{int(row['nfl_id'])}\"\n",
    "        instance = ipt[fid]\n",
    "        frame = row['frame_id']\n",
    "\n",
    "        x0, x1, x2 = build_inputs(instance, frame) # Input vectors\n",
    "        y = row[['x','y']].values.astype(np.float32) # Output vectors\n",
    "\n",
    "        data.append((x0, x1, x2, y))\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "# Custom Dataset Class\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, dat):\n",
    "        self.data = dat\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x0, x1, x2, y = self.data[idx]\n",
    "        return torch.tensor(x0), torch.tensor(x1), torch.tensor(x2), torch.tensor(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started loading training data\n",
      "Finished loading training data\n",
      "Started loading validation data\n",
      "Finished loading validation data\n",
      "Started loading testing data\n",
      "Finished loading testing data\n"
     ]
    }
   ],
   "source": [
    "# --- Train & Test Data ETL ---\n",
    "\n",
    "print(\"Started loading training data\")\n",
    "raw_input_train = [pd.read_csv(f'{base_path}/input_2023_w0{i}.csv') for i in range(1,num_weeks+1)]\n",
    "raw_output_train = [pd.read_csv(f'{base_path}/output_2023_w0{i}.csv') for i in range(1,num_weeks+1)]\n",
    "in_train = format_input(raw_input_train)\n",
    "out_train = pd.concat(raw_output_train, ignore_index=True)\n",
    "train_dataset = MyDataset(preprocess(out_train, in_train))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "print(\"Finished loading training data\")\n",
    "\n",
    "print(\"Started loading validation data\")\n",
    "raw_input_val = [pd.read_csv(f'{base_path}/input_2023_w{i}.csv') for i in range(16,18)]\n",
    "raw_output_val = [pd.read_csv(f'{base_path}/output_2023_w{i}.csv') for i in range(16,18)]\n",
    "in_val = format_input(raw_input_val)\n",
    "out_val = pd.concat(raw_output_val, ignore_index=True)\n",
    "val_dataset = MyDataset(preprocess(out_val, in_val))\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "print(\"Finished loading validation data\")\n",
    "\n",
    "print(\"Started loading testing data\")\n",
    "raw_input_test = [pd.read_csv(f'{base_path}/input_2023_w{i}.csv') for i in range(18,19)]\n",
    "raw_output_test = [pd.read_csv(f'{base_path}/output_2023_w{i}.csv') for i in range(18,19)]\n",
    "in_test = format_input(raw_input_test)\n",
    "out_test = pd.concat(raw_output_test, ignore_index=True)\n",
    "test_dataset = MyDataset(preprocess(out_test, in_test))\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "print(\"Finished loading testing data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model Initialization ---\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, x0_size=7, transformer_input_size=8, hidden_size=64, num_layers=3, mlp_output_size=2, nhead=8):\n",
    "        super().__init__()\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_size,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=hidden_size*4,\n",
    "            batch_first=True  # allows input shape (batch, seq_len, hidden_size)\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # linear layer to project x1 input to hidden_size\n",
    "        self.input_proj = nn.Linear(transformer_input_size, hidden_size)\n",
    "        \n",
    "        # MLP after concatenating last hidden with x0\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_size + x0_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, mlp_output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x0, x1, x2):\n",
    "        # project input to hidden_size\n",
    "        x1_proj = self.input_proj(x1)  # (batch, seq_len, hidden_size)\n",
    "        \n",
    "        # pass through transformer\n",
    "        out = self.transformer(x1_proj)  # (batch, seq_len, hidden_size)\n",
    "        last_hidden = out[:, -1, :]      # (batch, hidden_size), take last token\n",
    "        \n",
    "        # concatenate with x0\n",
    "        x0_expanded = x0.view(x0.size(0), -1)\n",
    "        combined = torch.cat([last_hidden, x0_expanded], dim=1)\n",
    "        \n",
    "        output = self.mlp(combined)\n",
    "        \n",
    "        # add x2\n",
    "        output = output + x2\n",
    "        \n",
    "        return output\n",
    "\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torch.load(\"V5.pth\", weights_only=False, map_location=device) if load_prev_model else torch.compile(Transformer().to(device))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.MSELoss(reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Approx Loss: 1.2490 Val Loss: 1.0876\n",
      "Epoch 2: Approx Loss: 0.9796 Val Loss: 1.0540\n",
      "Epoch 3: Approx Loss: 0.9222 Val Loss: 1.0005\n",
      "Epoch 4: Approx Loss: 0.8799 Val Loss: 0.9850\n",
      "Epoch 5: Approx Loss: 0.8531 Val Loss: 0.9743\n",
      "Epoch 6: Approx Loss: 0.8292 Val Loss: 1.0010\n",
      "Epoch 7: Approx Loss: 0.8123 Val Loss: 1.0457\n",
      "Epoch 8: Approx Loss: 0.7954 Val Loss: 0.9891\n",
      "Epoch 9: Approx Loss: 0.7856 Val Loss: 0.9964\n",
      "Epoch 10: Approx Loss: 0.7755 Val Loss: 1.0792\n"
     ]
    }
   ],
   "source": [
    "# --- Training Loop ---\n",
    "\n",
    "def val_loss():\n",
    "    model.eval()\n",
    "    total_se = 0.0 \n",
    "    total_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x0, x1, x2, y in val_loader:\n",
    "            x0, x1, x2, y = x0.to(device), x1.to(device), x2.to(device), y.to(device)\n",
    "            preds = model(x0, x1, x2)\n",
    "            se = (preds - y) ** 2\n",
    "            total_se += se.sum().item() \n",
    "            total_count += y.numel()\n",
    "\n",
    "    rmse = ((total_se / total_count) ** 0.5)\n",
    "    return rmse\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    for x0, x1, x2, y in train_loader:\n",
    "        x0, x1, x2, y = x0.to(device, non_blocking=True), x1.to(device, non_blocking=True), x2.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "        preds = model(x0, x1, x2)\n",
    "        loss = torch.sqrt(criterion(preds, y))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    v_loss = val_loss()\n",
    "    print(f\"Epoch {epoch+1}: Approx Loss: {total_loss / len(train_loader):.4f} Val Loss: {v_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 1.0244069435616274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# --- Test model ---\n",
    "total_se = 0.0\n",
    "total_count = 0\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x0, x1, x2, y in tqdm(test_loader, leave=False):\n",
    "        x0, x1, x2, y = x0.to(device), x1.to(device), x2.to(device), y.to(device)\n",
    "        preds = model(x0, x1, x2)\n",
    "        se = (preds - y) ** 2\n",
    "        total_se += se.sum().item()\n",
    "        total_count += y.numel()\n",
    "\n",
    "rmse = ((total_se / total_count) ** 0.5)\n",
    "print(f\"RMSE = {rmse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started importing submission inputs\n",
      "Finished importing submission inputs\n"
     ]
    }
   ],
   "source": [
    "# --- Submission data preprocessing ---\n",
    "\n",
    "# Submission inputs\n",
    "print(\"Started importing submission inputs\")\n",
    "instances = pd.read_csv('./kaggle/input/nfl-big-data-bowl-2026-prediction/test.csv')\n",
    "eval_in = pd.read_csv('./kaggle/input/nfl-big-data-bowl-2026-prediction/test_input.csv')\n",
    "eval_in = format_input([eval_in])\n",
    "print(\"Finished importing submission inputs\")\n",
    "\n",
    "# Process inputs for submission\n",
    "def prepare_inputs(row, ipt):\n",
    "    gid, pid, nid, fid = int(row['game_id']), int(row['play_id']), int(row['nfl_id']), int(row['frame_id'])\n",
    "    instance = ipt[f\"{gid}_{pid}_{nid}\"]\n",
    "\n",
    "    x0, x1, x2 = build_inputs(instance, fid)\n",
    "    return torch.tensor(x0).unsqueeze(0), torch.tensor(x1).unsqueeze(0), torch.tensor(x2).unsqueeze(0)\n",
    "\n",
    "# Predict positions for submission\n",
    "def compute_pos(row):\n",
    "    gid, pid, nid, fid = row['game_id'], row['play_id'], row['nfl_id'], row['frame_id']\n",
    "    full_id = f\"{gid}_{pid}_{nid}_{fid}\"\n",
    "\n",
    "    x0, x1, x2 = prepare_inputs(row, eval_in)\n",
    "    x0, x1, x2 = x0.to(device, non_blocking=True), x1.to(device, non_blocking=True), x2.to(device, non_blocking=True)\n",
    "\n",
    "    pred_x, pred_y = model(x0, x1, x2).squeeze(0).tolist()\n",
    "    return pd.Series([full_id, pred_x, pred_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started computing submission\n",
      "Finished computing submission\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024120805_74_54586_1</td>\n",
       "      <td>87.977875</td>\n",
       "      <td>34.147022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024120805_74_54586_2</td>\n",
       "      <td>88.441956</td>\n",
       "      <td>34.300583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024120805_74_54586_3</td>\n",
       "      <td>88.906029</td>\n",
       "      <td>34.454144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024120805_74_54586_4</td>\n",
       "      <td>89.332329</td>\n",
       "      <td>34.495369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024120805_74_54586_5</td>\n",
       "      <td>89.620613</td>\n",
       "      <td>34.601234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024120805_74_54586_6</td>\n",
       "      <td>89.971954</td>\n",
       "      <td>34.755505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024120805_74_54586_7</td>\n",
       "      <td>90.341591</td>\n",
       "      <td>34.923820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024120805_74_54586_8</td>\n",
       "      <td>90.696617</td>\n",
       "      <td>35.105747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024120805_74_54586_9</td>\n",
       "      <td>90.960915</td>\n",
       "      <td>35.441547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024120805_74_54586_10</td>\n",
       "      <td>91.230774</td>\n",
       "      <td>35.780663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id          x          y\n",
       "0   2024120805_74_54586_1  87.977875  34.147022\n",
       "1   2024120805_74_54586_2  88.441956  34.300583\n",
       "2   2024120805_74_54586_3  88.906029  34.454144\n",
       "3   2024120805_74_54586_4  89.332329  34.495369\n",
       "4   2024120805_74_54586_5  89.620613  34.601234\n",
       "5   2024120805_74_54586_6  89.971954  34.755505\n",
       "6   2024120805_74_54586_7  90.341591  34.923820\n",
       "7   2024120805_74_54586_8  90.696617  35.105747\n",
       "8   2024120805_74_54586_9  90.960915  35.441547\n",
       "9  2024120805_74_54586_10  91.230774  35.780663"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Final submission df ---\n",
    "model.eval()\n",
    "submission = instances.copy(deep=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(\"Started computing submission\")\n",
    "    submission[['id', 'x', 'y']] = submission.apply(compute_pos, axis=1)\n",
    "    print(\"Finished computing submission\")\n",
    "submission = submission[['id', 'x', 'y']]\n",
    "\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted!!!\n"
     ]
    }
   ],
   "source": [
    "# --- Submission to csv ---\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submitted!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started computing test\n",
      "Finished computing test\n"
     ]
    }
   ],
   "source": [
    "# --- Export for metric testing ---\n",
    "out_csv = out_test.copy(deep=True)\n",
    "out_csv['id'] = out_csv.apply(lambda r: f\"{int(r.game_id)}_{int(r.play_id)}_{int(r.nfl_id)}_{int(r.frame_id)}\", axis=1)\n",
    "out_csv = out_csv[['id', 'x', 'y']]\n",
    "out_csv.to_csv('testSolution.csv', index=False)\n",
    "\n",
    "# Process inputs for testing export\n",
    "def prepare_inputs_1(row, ipt):\n",
    "    gid, pid, nid, fid = int(row['game_id']), int(row['play_id']), int(row['nfl_id']), int(row['frame_id'])\n",
    "    out_test = ipt[f\"{gid}_{pid}_{nid}\"]\n",
    "\n",
    "    x0, x1, x2 = build_inputs(out_test, fid)\n",
    "    return torch.tensor(x0).unsqueeze(0), torch.tensor(x1).unsqueeze(0), torch.tensor(x2).unsqueeze(0)\n",
    "\n",
    "# Predict positions for submission\n",
    "def compute_pos_1(row):\n",
    "    gid, pid, nid, fid = row['game_id'], row['play_id'], row['nfl_id'], row['frame_id']\n",
    "    full_id = f\"{gid}_{pid}_{nid}_{fid}\"\n",
    "\n",
    "    x0, x1, x2 = prepare_inputs_1(row, in_test)\n",
    "    x0, x1, x2 = x0.to(device, non_blocking=True), x1.to(device, non_blocking=True), x2.to(device, non_blocking=True)\n",
    "\n",
    "    pred_x, pred_y = model(x0, x1, x2).squeeze(0).tolist()\n",
    "    return pd.Series([full_id, pred_x, pred_y])\n",
    "\n",
    "model.eval()\n",
    "pred_csv = out_test[['game_id', 'play_id', 'nfl_id', 'frame_id']].copy(deep=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(\"Started computing test\")\n",
    "    pred_csv[['id', 'x', 'y']] = pred_csv.apply(compute_pos_1, axis=1)\n",
    "    print(\"Finished computing test\")\n",
    "pred_csv = pred_csv[['id', 'x', 'y']]\n",
    "\n",
    "pred_csv.to_csv('testSubmission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"V5.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
