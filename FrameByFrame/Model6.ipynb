{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Global Variables and Hyperparameters ---\n",
    "base_path = './kaggle/input/nfl-big-data-bowl-2026-prediction/train'\n",
    "lr = .001\n",
    "num_epochs = 20\n",
    "batch_size = 64\n",
    "num_weeks = 15\n",
    "load_prev_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ETL Helpers ---\n",
    "\n",
    "# Input: Array of input dataframes\n",
    "# Output: Dictionary of dataframes grouped by id\n",
    "def format_input(input):\n",
    "    ipt = pd.concat(input, ignore_index=True) # Concatenate all dfs into one\n",
    "    ipt = ipt[ipt['player_to_predict'] == True].copy(deep=True) # Filter to only players that matter\n",
    "\n",
    "    # Add velocity component column\n",
    "    dir_rad = np.deg2rad(ipt['dir'])\n",
    "    ipt['vx'] = ipt['s'] * np.sin(dir_rad)\n",
    "    ipt['vy'] = ipt['s'] * np.cos(dir_rad)\n",
    "\n",
    "    # Add orientation components\n",
    "    o_rad = np.deg2rad(ipt['o'])\n",
    "    ipt['ox'] = np.sin(o_rad)\n",
    "    ipt['oy'] = np.cos(o_rad)\n",
    "\n",
    "    # Offense going left? 1 or -1\n",
    "    ipt['go_left'] = np.where(ipt['play_direction'] == 'left', 1, -1)\n",
    "\n",
    "    # Offensive player? 1 or -1\n",
    "    ipt['offensive_player'] = np.where(ipt['player_role'] == 'Targeted Receiver', 1, -1)\n",
    "\n",
    "    # Get useful columns only\n",
    "    # Constant variables: 'go_left', 'offensive_player', 'ball_land_x', 'ball_land_y', 'absolute_yardline_number', 'num_frames_output'\n",
    "    # Time variables : 'x', 'y', 'vx', 'vy', 'ox', 'oy', 'a', 'frame_id'\n",
    "    ipt = ipt[['game_id', 'play_id', 'nfl_id', 'x', 'y', 'vx', 'vy', 'ox', 'oy', 'go_left', 'offensive_player', 'a', 'ball_land_x', 'ball_land_y', 'absolute_yardline_number', 'frame_id', 'num_frames_output']]\n",
    "\n",
    "\n",
    "    # Create dictionary of dfs\n",
    "    ipt = {\n",
    "        f\"{gid}_{pid}_{nid}\": g\n",
    "        for (gid, pid, nid), g in ipt.groupby(['game_id', 'play_id', 'nfl_id'])\n",
    "    }\n",
    "    return ipt\n",
    "\n",
    "\n",
    "# Input: \n",
    "    # instance: Dataframe specific to game, nfl, and player ids\n",
    "    # frame: Current frame used for prediction\n",
    "# Output: List of (x0, x1, x2)\n",
    "    # x0, First input vector\n",
    "    # x1: First input array\n",
    "    # x2: Second input vector\n",
    "def build_inputs(instance, frame):\n",
    "    x0 = instance.iloc[-1][['go_left', 'offensive_player', 'ball_land_x', 'ball_land_y','absolute_yardline_number', 'num_frames_output']].values \n",
    "    x0 = np.concatenate([x0, [frame]]).astype(np.float32)#np(7,)\n",
    "    x1 = instance.iloc[-6:][['x','y','vx','vy','ox','oy','a','frame_id']].values.astype(np.float32) #np(6,8))\n",
    "    x2v = instance.iloc[-1][['vx', 'vy']].values.astype(np.float32)*frame.astype(np.float32)*.1\n",
    "    x2p = instance.iloc[-1][['x','y']].values.astype(np.float32) #np(2,)\n",
    "    x2 = x2v+x2p\n",
    "    return x0, x1, x2\n",
    "\n",
    "\n",
    "\n",
    "# Input: \n",
    "    # out: Target dataframe (use only to extract ids and get frame id)\n",
    "    # ipt: Dictionary of input dfs\n",
    "# Output: List of (x0, x1, x2, y)\n",
    "    # x0: First input vector\n",
    "    # x1: First input array\n",
    "    # x2: Second input vector\n",
    "    # y: Target vector\n",
    "def preprocess(out, ipt):\n",
    "    data = []\n",
    "    for _, row in out.iterrows():\n",
    "        fid = f\"{int(row['game_id'])}_{int(row['play_id'])}_{int(row['nfl_id'])}\"\n",
    "        instance = ipt[fid]\n",
    "        frame = row['frame_id']\n",
    "\n",
    "        x0, x1, x2 = build_inputs(instance, frame) # Input vectors\n",
    "        y = row[['x','y']].values.astype(np.float32) # Output vectors\n",
    "\n",
    "        data.append((x0, x1, x2, y))\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "# Custom Dataset Class\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, dat):\n",
    "        self.data = dat\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x0, x1, x2, y = self.data[idx]\n",
    "        return torch.tensor(x0), torch.tensor(x1), torch.tensor(x2), torch.tensor(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started loading training data\n",
      "Finished loading training data\n",
      "Started loading validation data\n",
      "Finished loading validation data\n",
      "Started loading testing data\n",
      "Finished loading testing data\n"
     ]
    }
   ],
   "source": [
    "# --- Train & Test Data ETL ---\n",
    "\n",
    "print(\"Started loading training data\")\n",
    "raw_input_train = [pd.read_csv(f'{base_path}/input_2023_w{i:02}.csv') for i in range(1,num_weeks+1)]\n",
    "raw_output_train = [pd.read_csv(f'{base_path}/output_2023_w{i:02}.csv') for i in range(1,num_weeks+1)]\n",
    "in_train = format_input(raw_input_train)\n",
    "out_train = pd.concat(raw_output_train, ignore_index=True)\n",
    "train_dataset = MyDataset(preprocess(out_train, in_train))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "print(\"Finished loading training data\")\n",
    "\n",
    "print(\"Started loading validation data\")\n",
    "raw_input_val = [pd.read_csv(f'{base_path}/input_2023_w{i}.csv') for i in range(16,18)]\n",
    "raw_output_val = [pd.read_csv(f'{base_path}/output_2023_w{i}.csv') for i in range(16,18)]\n",
    "in_val = format_input(raw_input_val)\n",
    "out_val = pd.concat(raw_output_val, ignore_index=True)\n",
    "val_dataset = MyDataset(preprocess(out_val, in_val))\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "print(\"Finished loading validation data\")\n",
    "\n",
    "print(\"Started loading testing data\")\n",
    "raw_input_test = [pd.read_csv(f'{base_path}/input_2023_w{i}.csv') for i in range(18,19)]\n",
    "raw_output_test = [pd.read_csv(f'{base_path}/output_2023_w{i}.csv') for i in range(18,19)]\n",
    "in_test = format_input(raw_input_test)\n",
    "out_test = pd.concat(raw_output_test, ignore_index=True)\n",
    "test_dataset = MyDataset(preprocess(out_test, in_test))\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "print(\"Finished loading testing data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model Initialization ---\n",
    "\n",
    "\n",
    "class MixedModel(nn.Module):\n",
    "    def __init__(self, x0_size=7, lstm_input_size=8, hidden_size=32, num_layers=2, mlp_output_size=2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=lstm_input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.mlp1 = nn.Sequential(\n",
    "            nn.Linear(hidden_size + x0_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, mlp_output_size)\n",
    "        )\n",
    "\n",
    "        self.mlp2 = nn.Sequential(\n",
    "            nn.Linear(55, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, mlp_output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x0, x1, x2):\n",
    "        # x1: (batch, seq_len, lstm_input_size)\n",
    "        out, (h_n, c_n) = self.lstm(x1)\n",
    "        last_hidden = h_n[-1]  # (batch, hidden_size)\n",
    "        # concatenate last_hidden with x0\n",
    "        combined = torch.cat([last_hidden, x0], dim=1)  # (batch, hidden_size + x0_size)\n",
    "        output_rnn = self.mlp1(combined)  # (batch, mlp_output_size)\n",
    "\n",
    "        mod_x0 = x1.flatten(start_dim=1)\n",
    "        mod_x0 = torch.cat([mod_x0, x0], dim=1)\n",
    "        output_mlp = self.mlp2(mod_x0)\n",
    "\n",
    "        # add x2\n",
    "        #output = output_rnn + output_mlp + x2\n",
    "        output = output_mlp + x2\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torch.load(\"V6.pth\", weights_only=False, map_location=device) if load_prev_model else torch.compile(MixedModel().to(device))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.MSELoss(reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Approx Loss: 1.1311 Val Loss: 1.1184\n",
      "Epoch 2: Approx Loss: 0.9355 Val Loss: 1.0772\n",
      "Epoch 3: Approx Loss: 0.8991 Val Loss: 1.0544\n",
      "Epoch 4: Approx Loss: 0.8717 Val Loss: 1.0322\n",
      "Epoch 5: Approx Loss: 0.8538 Val Loss: 1.0069\n",
      "Epoch 6: Approx Loss: 0.8384 Val Loss: 1.0186\n",
      "Epoch 7: Approx Loss: 0.8257 Val Loss: 0.9860\n",
      "Epoch 8: Approx Loss: 0.8133 Val Loss: 0.9784\n",
      "Epoch 9: Approx Loss: 0.8066 Val Loss: 0.9831\n",
      "Epoch 10: Approx Loss: 0.7997 Val Loss: 0.9756\n",
      "Epoch 11: Approx Loss: 0.7875 Val Loss: 0.9589\n",
      "Epoch 12: Approx Loss: 0.7828 Val Loss: 0.9455\n",
      "Epoch 13: Approx Loss: 0.7741 Val Loss: 0.9463\n",
      "Epoch 14: Approx Loss: 0.7726 Val Loss: 0.9308\n",
      "Epoch 15: Approx Loss: 0.7665 Val Loss: 0.9444\n",
      "Epoch 16: Approx Loss: 0.7617 Val Loss: 0.9165\n",
      "Epoch 17: Approx Loss: 0.7557 Val Loss: 0.9101\n",
      "Epoch 18: Approx Loss: 0.7561 Val Loss: 0.9190\n",
      "Epoch 19: Approx Loss: 0.7530 Val Loss: 0.9299\n",
      "Epoch 20: Approx Loss: 0.7497 Val Loss: 0.9088\n"
     ]
    }
   ],
   "source": [
    "# --- Training Loop ---\n",
    "\n",
    "def val_loss():\n",
    "    model.eval()\n",
    "    total_se = 0.0 \n",
    "    total_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x0, x1, x2, y in val_loader:\n",
    "            x0, x1, x2, y = x0.to(device), x1.to(device), x2.to(device), y.to(device)\n",
    "            preds = model(x0, x1, x2)\n",
    "            se = (preds - y) ** 2\n",
    "            total_se += se.sum().item() \n",
    "            total_count += y.numel()\n",
    "\n",
    "    rmse = ((total_se / total_count) ** 0.5)\n",
    "    return rmse\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    for x0, x1, x2, y in train_loader:\n",
    "        x0, x1, x2, y = x0.to(device, non_blocking=True), x1.to(device, non_blocking=True), x2.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "        preds = model(x0, x1, x2)\n",
    "        loss = torch.sqrt(criterion(preds, y))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    v_loss = val_loss()\n",
    "    print(f\"Epoch {epoch+1}: Approx Loss: {total_loss / len(train_loader):.4f} Val Loss: {v_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 0.7128133067585626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# --- Test model ---\n",
    "total_se = 0.0\n",
    "total_count = 0\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x0, x1, x2, y in tqdm(test_loader, leave=False):\n",
    "        x0, x1, x2, y = x0.to(device), x1.to(device), x2.to(device), y.to(device)\n",
    "        preds = model(x0, x1, x2)\n",
    "        se = (preds - y) ** 2\n",
    "        total_se += se.sum().item()\n",
    "        total_count += y.numel()\n",
    "\n",
    "rmse = ((total_se / total_count) ** 0.5)\n",
    "print(f\"RMSE = {rmse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started importing submission inputs\n",
      "Finished importing submission inputs\n"
     ]
    }
   ],
   "source": [
    "# --- Submission data preprocessing ---\n",
    "\n",
    "# Submission inputs\n",
    "print(\"Started importing submission inputs\")\n",
    "instances = pd.read_csv('./kaggle/input/nfl-big-data-bowl-2026-prediction/test.csv')\n",
    "eval_in = pd.read_csv('./kaggle/input/nfl-big-data-bowl-2026-prediction/test_input.csv')\n",
    "eval_in = format_input([eval_in])\n",
    "print(\"Finished importing submission inputs\")\n",
    "\n",
    "# Process inputs for submission\n",
    "def prepare_inputs(row, ipt):\n",
    "    gid, pid, nid, fid = int(row['game_id']), int(row['play_id']), int(row['nfl_id']), int(row['frame_id'])\n",
    "    instance = ipt[f\"{gid}_{pid}_{nid}\"]\n",
    "\n",
    "    x0, x1, x2 = build_inputs(instance, fid)\n",
    "    return torch.tensor(x0).unsqueeze(0), torch.tensor(x1).unsqueeze(0), torch.tensor(x2).unsqueeze(0)\n",
    "\n",
    "# Predict positions for submission\n",
    "def compute_pos(row):\n",
    "    gid, pid, nid, fid = row['game_id'], row['play_id'], row['nfl_id'], row['frame_id']\n",
    "    full_id = f\"{gid}_{pid}_{nid}_{fid}\"\n",
    "\n",
    "    x0, x1, x2 = prepare_inputs(row, eval_in)\n",
    "    x0, x1, x2 = x0.to(device, non_blocking=True), x1.to(device, non_blocking=True), x2.to(device, non_blocking=True)\n",
    "\n",
    "    pred_x, pred_y = model(x0, x1, x2).squeeze(0).tolist()\n",
    "    return pd.Series([full_id, pred_x, pred_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started computing submission\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarted computing submission\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     submission[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m submission\u001b[38;5;241m.\u001b[39mapply(compute_pos, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished computing submission\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m submission \u001b[38;5;241m=\u001b[39m submission[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mapply()\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_generator()\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(v, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[12], line 23\u001b[0m, in \u001b[0;36mcompute_pos\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     20\u001b[0m gid, pid, nid, fid \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgame_id\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplay_id\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnfl_id\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     21\u001b[0m full_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 23\u001b[0m x0, x1, x2 \u001b[38;5;241m=\u001b[39m prepare_inputs(row, eval_in)\n\u001b[1;32m     24\u001b[0m x0, x1, x2 \u001b[38;5;241m=\u001b[39m x0\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), x1\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), x2\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     26\u001b[0m pred_x, pred_y \u001b[38;5;241m=\u001b[39m model(x0, x1, x2)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()\n",
      "Cell \u001b[0;32mIn[12], line 15\u001b[0m, in \u001b[0;36mprepare_inputs\u001b[0;34m(row, ipt)\u001b[0m\n\u001b[1;32m     12\u001b[0m gid, pid, nid, fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgame_id\u001b[39m\u001b[38;5;124m'\u001b[39m]), \u001b[38;5;28mint\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplay_id\u001b[39m\u001b[38;5;124m'\u001b[39m]), \u001b[38;5;28mint\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnfl_id\u001b[39m\u001b[38;5;124m'\u001b[39m]), \u001b[38;5;28mint\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe_id\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     13\u001b[0m instance \u001b[38;5;241m=\u001b[39m ipt[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 15\u001b[0m x0, x1, x2 \u001b[38;5;241m=\u001b[39m build_inputs(instance, fid)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(x0)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m), torch\u001b[38;5;241m.\u001b[39mtensor(x1)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m), torch\u001b[38;5;241m.\u001b[39mtensor(x2)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 50\u001b[0m, in \u001b[0;36mbuild_inputs\u001b[0;34m(instance, frame)\u001b[0m\n\u001b[1;32m     48\u001b[0m x0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([x0, [frame]])\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;66;03m#np(7,)\u001b[39;00m\n\u001b[1;32m     49\u001b[0m x1 \u001b[38;5;241m=\u001b[39m instance\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m6\u001b[39m:][[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvx\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvy\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mox\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moy\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe_id\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;66;03m#np(6,8))\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m x2v \u001b[38;5;241m=\u001b[39m instance\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvy\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m*\u001b[39mframe\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m.1\u001b[39m\n\u001b[1;32m     51\u001b[0m x2p \u001b[38;5;241m=\u001b[39m instance\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;66;03m#np(2,)\u001b[39;00m\n\u001b[1;32m     52\u001b[0m x2 \u001b[38;5;241m=\u001b[39m x2v\u001b[38;5;241m+\u001b[39mx2p\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "# --- Final submission df ---\n",
    "model.eval()\n",
    "submission = instances.copy(deep=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(\"Started computing submission\")\n",
    "    submission[['id', 'x', 'y']] = submission.apply(compute_pos, axis=1)\n",
    "    print(\"Finished computing submission\")\n",
    "submission = submission[['id', 'x', 'y']]\n",
    "\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted!!!\n"
     ]
    }
   ],
   "source": [
    "# --- Submission to csv ---\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submitted!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started computing test\n",
      "Finished computing test\n"
     ]
    }
   ],
   "source": [
    "# --- Export for metric testing ---\n",
    "out_csv = out_test.copy(deep=True)\n",
    "out_csv['id'] = out_csv.apply(lambda r: f\"{int(r.game_id)}_{int(r.play_id)}_{int(r.nfl_id)}_{int(r.frame_id)}\", axis=1)\n",
    "out_csv = out_csv[['id', 'x', 'y']]\n",
    "out_csv.to_csv('testSolution.csv', index=False)\n",
    "\n",
    "# Process inputs for testing export\n",
    "def prepare_inputs_1(row, ipt):\n",
    "    gid, pid, nid, fid = int(row['game_id']), int(row['play_id']), int(row['nfl_id']), int(row['frame_id'])\n",
    "    out_test = ipt[f\"{gid}_{pid}_{nid}\"]\n",
    "\n",
    "    x0, x1, x2 = build_inputs(out_test, fid)\n",
    "    return torch.tensor(x0).unsqueeze(0), torch.tensor(x1).unsqueeze(0), torch.tensor(x2).unsqueeze(0)\n",
    "\n",
    "# Predict positions for submission\n",
    "def compute_pos_1(row):\n",
    "    gid, pid, nid, fid = row['game_id'], row['play_id'], row['nfl_id'], row['frame_id']\n",
    "    full_id = f\"{gid}_{pid}_{nid}_{fid}\"\n",
    "\n",
    "    x0, x1, x2 = prepare_inputs_1(row, in_test)\n",
    "    x0, x1, x2 = x0.to(device, non_blocking=True), x1.to(device, non_blocking=True), x2.to(device, non_blocking=True)\n",
    "\n",
    "    pred_x, pred_y = model(x0, x1, x2).squeeze(0).tolist()\n",
    "    return pd.Series([full_id, pred_x, pred_y])\n",
    "\n",
    "model.eval()\n",
    "pred_csv = out_test[['game_id', 'play_id', 'nfl_id', 'frame_id']].copy(deep=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(\"Started computing test\")\n",
    "    pred_csv[['id', 'x', 'y']] = pred_csv.apply(compute_pos_1, axis=1)\n",
    "    print(\"Finished computing test\")\n",
    "pred_csv = pred_csv[['id', 'x', 'y']]\n",
    "\n",
    "pred_csv.to_csv('testSubmission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"V6.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
