{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Network with documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Global Variables and Hyperparameters ---\n",
    "base_path = './kaggle/input/nfl-big-data-bowl-2026-prediction/train'\n",
    "lr = .001\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "num_weeks = 15\n",
    "load_prev_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ETL Helpers ---\n",
    "\n",
    "# Input: Array of input dataframes\n",
    "# Output: Dictionary of dataframes grouped by id\n",
    "def format_input(input):\n",
    "    ipt = pd.concat(input, ignore_index=True) # Concatenate all dfs into one\n",
    "    ipt = ipt[ipt['player_to_predict'] == True].copy(deep=True) # Filter to only players that matter\n",
    "\n",
    "    # Add velocity component column\n",
    "    dir_rad = np.deg2rad(ipt['dir'])\n",
    "    ipt['vx'] = ipt['s'] * np.sin(dir_rad)\n",
    "    ipt['vy'] = ipt['s'] * np.cos(dir_rad)\n",
    "\n",
    "    # Add orientation components\n",
    "    o_rad = np.deg2rad(ipt['o'])\n",
    "    ipt['ox'] = np.sin(o_rad)\n",
    "    ipt['oy'] = np.cos(o_rad)\n",
    "\n",
    "    # Offense going left? 1 or -1\n",
    "    ipt['go_left'] = np.where(ipt['play_direction'] == 'left', 1, -1)\n",
    "\n",
    "    # Offensive player? 1 or -1\n",
    "    ipt['offensive_player'] = np.where(ipt['player_role'] == 'Targeted Receiver', 1, -1)\n",
    "\n",
    "    # Get useful columns only\n",
    "    # Constant variables: 'go_left', 'offensive_player', 'ball_land_x', 'ball_land_y', 'absolute_yardline_number', 'num_frames_output'\n",
    "    # Time variables : 'x', 'y', 'vx', 'vy', 'ox', 'oy', 'a', 'frame_id'\n",
    "    ipt = ipt[['game_id', 'play_id', 'nfl_id', 'x', 'y', 'vx', 'vy', 'ox', 'oy', 'go_left', 'offensive_player', 'a', 'ball_land_x', 'ball_land_y', 'absolute_yardline_number', 'frame_id', 'num_frames_output']]\n",
    "\n",
    "\n",
    "    # Create dictionary of dfs\n",
    "    ipt = {\n",
    "        f\"{gid}_{pid}_{nid}\": g\n",
    "        for (gid, pid, nid), g in ipt.groupby(['game_id', 'play_id', 'nfl_id'])\n",
    "    }\n",
    "    return ipt\n",
    "\n",
    "\n",
    "# Input: \n",
    "    # instance: Dataframe specific to game, nfl, and player ids\n",
    "    # frame: Current frame used for prediction\n",
    "# Output: List of (x0, x1, x2)\n",
    "    # x0, First input vector\n",
    "    # x1: First input array\n",
    "    # x2: Second input vector\n",
    "def build_inputs(instance, frame):\n",
    "    x0 = instance.iloc[-1][['go_left', 'offensive_player', 'ball_land_x', 'ball_land_y','absolute_yardline_number', 'num_frames_output']].values \n",
    "    x0 = np.concatenate([x0, [frame]]).astype(np.float32)#np(7,)\n",
    "    x1 = instance.iloc[-6:][['x','y','vx','vy','ox','oy','a','frame_id']].values.astype(np.float32) #np(5,8))\n",
    "    x2v = instance.iloc[-1][['vx', 'vy']].values.astype(np.float32)*frame.astype(np.float32)*.1\n",
    "    x2p = instance.iloc[-1][['x','y']].values.astype(np.float32) #np(2,)\n",
    "    x2 = x2v+x2p\n",
    "    return x0, x1, x2\n",
    "\n",
    "\n",
    "\n",
    "# Input: \n",
    "    # out: Target dataframe (use only to extract ids and get frame id)\n",
    "    # ipt: Dictionary of input dfs\n",
    "# Output: List of (x0, x1, x2, y)\n",
    "    # x0: First input vector\n",
    "    # x1: First input array\n",
    "    # x2: Second input vector\n",
    "    # y: Target vector\n",
    "def preprocess(out, ipt):\n",
    "    data = []\n",
    "    for _, row in out.iterrows():\n",
    "        fid = f\"{int(row['game_id'])}_{int(row['play_id'])}_{int(row['nfl_id'])}\"\n",
    "        instance = ipt[fid]\n",
    "        frame = row['frame_id']\n",
    "\n",
    "        x0, x1, x2 = build_inputs(instance, frame) # Input vectors\n",
    "        y = row[['x','y']].values.astype(np.float32) # Output vectors\n",
    "\n",
    "        data.append((x0, x1, x2, y))\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "# Custom Dataset Class\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, dat):\n",
    "        self.data = dat\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x0, x1, x2, y = self.data[idx]\n",
    "        return torch.tensor(x0), torch.tensor(x1), torch.tensor(x2), torch.tensor(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started loading training data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ExactWeakKeyDictionary.__setitem__.<locals>.<lambda> at 0x39b10fd80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/_dynamo/utils.py\", line 542, in <lambda>\n",
      "    self.refs[idx] = weakref.ref(key, lambda ref: self._remove_id(idx))\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "# --- Train & Test Data ETL ---\n",
    "\n",
    "print(\"Started loading training data\")\n",
    "raw_input_train = [pd.read_csv(f'{base_path}/input_2023_w{i:02}.csv') for i in range(1,num_weeks+1)]\n",
    "raw_output_train = [pd.read_csv(f'{base_path}/output_2023_w{i:02}.csv') for i in range(1,num_weeks+1)]\n",
    "in_train = format_input(raw_input_train)\n",
    "out_train = pd.concat(raw_output_train, ignore_index=True)\n",
    "train_dataset = MyDataset(preprocess(out_train, in_train))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "print(\"Finished loading training data\")\n",
    "\n",
    "print(\"Started loading validation data\")\n",
    "raw_input_val = [pd.read_csv(f'{base_path}/input_2023_w{i}.csv') for i in range(16,18)]\n",
    "raw_output_val = [pd.read_csv(f'{base_path}/output_2023_w{i}.csv') for i in range(16,18)]\n",
    "in_val = format_input(raw_input_val)\n",
    "out_val = pd.concat(raw_output_val, ignore_index=True)\n",
    "val_dataset = MyDataset(preprocess(out_val, in_val))\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "print(\"Finished loading validation data\")\n",
    "\n",
    "print(\"Started loading testing data\")\n",
    "raw_input_test = [pd.read_csv(f'{base_path}/input_2023_w{i}.csv') for i in range(18,19)]\n",
    "raw_output_test = [pd.read_csv(f'{base_path}/output_2023_w{i}.csv') for i in range(18,19)]\n",
    "in_test = format_input(raw_input_test)\n",
    "out_test = pd.concat(raw_output_test, ignore_index=True)\n",
    "test_dataset = MyDataset(preprocess(out_test, in_test))\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "print(\"Finished loading testing data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model Initialization ---\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=8, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # after concatenating last_hidden with x0, input size for MLP becomes hidden_size + x0_size\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(71, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x0, x1, x2):\n",
    "        x1 = x1.permute(0, 2, 1)\n",
    "        cnn_out = self.cnn(x1)\n",
    "        cnn_out = F.adaptive_avg_pool1d(cnn_out, 1).squeeze(-1)\n",
    "        \n",
    "        # concatenate last_hidden with x0\n",
    "        combined = torch.cat([cnn_out, x0], dim=1)  # (batch, hidden_size + x0_size)\n",
    "        output = self.mlp(combined)  # (batch, mlp_output_size)\n",
    "        \n",
    "        # add x2\n",
    "        output = output + x2\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torch.load(\"V7.pth\", weights_only=False, map_location=device) if load_prev_model else torch.compile(CNN().to(device))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.MSELoss(reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Approx Loss: 1.0387 Val Loss: 1.0942\n",
      "Epoch 2: Approx Loss: 0.8742 Val Loss: 1.0014\n",
      "Epoch 3: Approx Loss: 0.7991 Val Loss: 0.9301\n",
      "Epoch 4: Approx Loss: 0.7464 Val Loss: 0.9066\n",
      "Epoch 5: Approx Loss: 0.7098 Val Loss: 0.9069\n",
      "Epoch 6: Approx Loss: 0.6832 Val Loss: 0.8952\n",
      "Epoch 7: Approx Loss: 0.6600 Val Loss: 0.9015\n",
      "Epoch 8: Approx Loss: 0.6396 Val Loss: 0.9298\n",
      "Epoch 9: Approx Loss: 0.6209 Val Loss: 0.8926\n",
      "Epoch 10: Approx Loss: 0.6081 Val Loss: 0.8998\n"
     ]
    }
   ],
   "source": [
    "# --- Training Loop ---\n",
    "\n",
    "def val_loss():\n",
    "    model.eval()\n",
    "    total_se = 0.0 \n",
    "    total_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x0, x1, x2, y in val_loader:\n",
    "            x0, x1, x2, y = x0.to(device), x1.to(device), x2.to(device), y.to(device)\n",
    "            preds = model(x0, x1, x2)\n",
    "            se = (preds - y) ** 2\n",
    "            total_se += se.sum().item() \n",
    "            total_count += y.numel()\n",
    "\n",
    "    rmse = ((total_se / total_count) ** 0.5)\n",
    "    return rmse\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    for x0, x1, x2, y in train_loader:\n",
    "        x0, x1, x2, y = x0.to(device, non_blocking=True), x1.to(device, non_blocking=True), x2.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "        preds = model(x0, x1, x2)\n",
    "        loss = torch.sqrt(criterion(preds, y))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    v_loss = val_loss()\n",
    "    print(f\"Epoch {epoch+1}: Approx Loss: {total_loss / len(train_loader):.4f} Val Loss: {v_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 0.7593112445395899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# --- Test model ---\n",
    "total_se = 0.0\n",
    "total_count = 0\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x0, x1, x2, y in tqdm(test_loader, leave=False):\n",
    "        x0, x1, x2, y = x0.to(device), x1.to(device), x2.to(device), y.to(device)\n",
    "        preds = model(x0, x1, x2)\n",
    "        se = (preds - y) ** 2\n",
    "        total_se += se.sum().item()\n",
    "        total_count += y.numel()\n",
    "\n",
    "rmse = ((total_se / total_count) ** 0.5)\n",
    "print(f\"RMSE = {rmse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started importing submission inputs\n",
      "Finished importing submission inputs\n"
     ]
    }
   ],
   "source": [
    "# --- Submission data preprocessing ---\n",
    "\n",
    "# Submission inputs\n",
    "print(\"Started importing submission inputs\")\n",
    "instances = pd.read_csv('./kaggle/input/nfl-big-data-bowl-2026-prediction/test.csv')\n",
    "eval_in = pd.read_csv('./kaggle/input/nfl-big-data-bowl-2026-prediction/test_input.csv')\n",
    "eval_in = format_input([eval_in])\n",
    "print(\"Finished importing submission inputs\")\n",
    "\n",
    "# Process inputs for submission\n",
    "def prepare_inputs(row, ipt):\n",
    "    gid, pid, nid, fid = int(row['game_id']), int(row['play_id']), int(row['nfl_id']), int(row['frame_id'])\n",
    "    instance = ipt[f\"{gid}_{pid}_{nid}\"]\n",
    "\n",
    "    x0, x1, x2 = build_inputs(instance, fid)\n",
    "    return torch.tensor(x0).unsqueeze(0), torch.tensor(x1).unsqueeze(0), torch.tensor(x2).unsqueeze(0)\n",
    "\n",
    "# Predict positions for submission\n",
    "def compute_pos(row):\n",
    "    gid, pid, nid, fid = row['game_id'], row['play_id'], row['nfl_id'], row['frame_id']\n",
    "    full_id = f\"{gid}_{pid}_{nid}_{fid}\"\n",
    "\n",
    "    x0, x1, x2 = prepare_inputs(row, eval_in)\n",
    "    x0, x1, x2 = x0.to(device, non_blocking=True), x1.to(device, non_blocking=True), x2.to(device, non_blocking=True)\n",
    "\n",
    "    pred_x, pred_y = model(x0, x1, x2).squeeze(0).tolist()\n",
    "    return pd.Series([full_id, pred_x, pred_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started computing submission\n",
      "Finished computing submission\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024120805_74_54586_1</td>\n",
       "      <td>88.259628</td>\n",
       "      <td>34.494099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024120805_74_54586_2</td>\n",
       "      <td>88.644180</td>\n",
       "      <td>34.478016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024120805_74_54586_3</td>\n",
       "      <td>88.981369</td>\n",
       "      <td>34.494831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024120805_74_54586_4</td>\n",
       "      <td>89.272224</td>\n",
       "      <td>34.607929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024120805_74_54586_5</td>\n",
       "      <td>89.545021</td>\n",
       "      <td>34.741631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024120805_74_54586_6</td>\n",
       "      <td>89.945152</td>\n",
       "      <td>35.004810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024120805_74_54586_7</td>\n",
       "      <td>90.429848</td>\n",
       "      <td>35.281693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024120805_74_54586_8</td>\n",
       "      <td>90.868385</td>\n",
       "      <td>35.457680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024120805_74_54586_9</td>\n",
       "      <td>91.301453</td>\n",
       "      <td>35.629375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024120805_74_54586_10</td>\n",
       "      <td>91.691368</td>\n",
       "      <td>35.943279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id          x          y\n",
       "0   2024120805_74_54586_1  88.259628  34.494099\n",
       "1   2024120805_74_54586_2  88.644180  34.478016\n",
       "2   2024120805_74_54586_3  88.981369  34.494831\n",
       "3   2024120805_74_54586_4  89.272224  34.607929\n",
       "4   2024120805_74_54586_5  89.545021  34.741631\n",
       "5   2024120805_74_54586_6  89.945152  35.004810\n",
       "6   2024120805_74_54586_7  90.429848  35.281693\n",
       "7   2024120805_74_54586_8  90.868385  35.457680\n",
       "8   2024120805_74_54586_9  91.301453  35.629375\n",
       "9  2024120805_74_54586_10  91.691368  35.943279"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Final submission df ---\n",
    "model.eval()\n",
    "submission = instances.copy(deep=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(\"Started computing submission\")\n",
    "    submission[['id', 'x', 'y']] = submission.apply(compute_pos, axis=1)\n",
    "    print(\"Finished computing submission\")\n",
    "submission = submission[['id', 'x', 'y']]\n",
    "\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted!!!\n"
     ]
    }
   ],
   "source": [
    "# --- Submission to csv ---\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submitted!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started computing test\n",
      "Finished computing test\n"
     ]
    }
   ],
   "source": [
    "# --- Export for metric testing ---\n",
    "out_csv = out_test.copy(deep=True)\n",
    "out_csv['id'] = out_csv.apply(lambda r: f\"{int(r.game_id)}_{int(r.play_id)}_{int(r.nfl_id)}_{int(r.frame_id)}\", axis=1)\n",
    "out_csv = out_csv[['id', 'x', 'y']]\n",
    "out_csv.to_csv('testSolution.csv', index=False)\n",
    "\n",
    "# Process inputs for testing export\n",
    "def prepare_inputs_1(row, ipt):\n",
    "    gid, pid, nid, fid = int(row['game_id']), int(row['play_id']), int(row['nfl_id']), int(row['frame_id'])\n",
    "    out_test = ipt[f\"{gid}_{pid}_{nid}\"]\n",
    "\n",
    "    x0, x1, x2 = build_inputs(out_test, fid)\n",
    "    return torch.tensor(x0).unsqueeze(0), torch.tensor(x1).unsqueeze(0), torch.tensor(x2).unsqueeze(0)\n",
    "\n",
    "# Predict positions for submission\n",
    "def compute_pos_1(row):\n",
    "    gid, pid, nid, fid = row['game_id'], row['play_id'], row['nfl_id'], row['frame_id']\n",
    "    full_id = f\"{gid}_{pid}_{nid}_{fid}\"\n",
    "\n",
    "    x0, x1, x2 = prepare_inputs_1(row, in_test)\n",
    "    x0, x1, x2 = x0.to(device, non_blocking=True), x1.to(device, non_blocking=True), x2.to(device, non_blocking=True)\n",
    "\n",
    "    pred_x, pred_y = model(x0, x1, x2).squeeze(0).tolist()\n",
    "    return pd.Series([full_id, pred_x, pred_y])\n",
    "\n",
    "model.eval()\n",
    "pred_csv = out_test[['game_id', 'play_id', 'nfl_id', 'frame_id']].copy(deep=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(\"Started computing test\")\n",
    "    pred_csv[['id', 'x', 'y']] = pred_csv.apply(compute_pos_1, axis=1)\n",
    "    print(\"Finished computing test\")\n",
    "pred_csv = pred_csv[['id', 'x', 'y']]\n",
    "\n",
    "pred_csv.to_csv('testSubmission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"V7.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
